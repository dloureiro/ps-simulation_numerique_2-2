<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
</head>
<body>
<h1 id="la-simulation-numérique-22">La simulation numérique 2/2</h1>
<p>Maintenant que nous avons expliqué dans le précédent podcast les besoins de simulation, les problématiques rencontrées avec différents champs de recherche et la première simulation numérique de l'histoire (finir par le hasard et les probabilités et toutes ces choses que je déteste personnellement a été dur pour moi) nous allons retourner sur des équations déterministes.</p>
<h2 id="rappel-sur-les-types-de-simulation">Rappel sur les types de simulation</h2>
<p>Je ne l'avais pas forcément expliqué, mais il y a plusieurs types de simulation numériques possibles <sup><a href="#fn1" class="footnoteRef" id="fnref1">1</a></sup> :</p>
<ul>
<li>La simulation discrète dans laquelle le système est soumis à une succession d’évènements qui le modifient. Ces simulations ont vocation à appliquer des principes simples à des systèmes de grande taille. La simulation discrète se divise en deux grandes catégories :
<ul>
<li>asynchrone ou time-slicing : on simule à chaque fois le passage d’une unité de temps sur tout le système. Ce terme n'est généralement plus utilisé dans le domaine professionnel depuis l'apparition croissante des nouvelles technologies.</li>
<li>synchrone ou event-sequencing : on calcule l’arrivée du prochain événement, et on ne simule qu’événement par événement, ce qui permet souvent des simulations rapides, bien qu’un peu plus complexes à programmer.</li>
</ul></li>
<li>La simulation par agents, où la simulation est segmentée en différentes entités qui interagissent entre elles. Elle est surtout utilisée dans les simulations économiques et sociales, où chaque agent représente un individu ou un groupe d’individus. Par nature, son fonctionnement est asynchrone.</li>
<li>La simulation continue, où le système se présente sous la forme d’équations différentielles à résoudre.</li>
</ul>
<p>Dans la suite de ce podcast, je vais sûrement me pencher sur la simulation continue.</p>
<p>Il existe d'ailleurs différentes méthodes de simulation, avec par exemple les méthodes de monte-carlo comme nous l'avons vu dans le précédent podcast, mais aussi les simulation atomistiques (pour certaines appelées ab initio) dont un exemple serait l'étude de l'eau avec un travail au niveau des atomes, puis des molécules, puis de la masse globale ou encore celles dont je vais parler qui sont les méthodes de discrétisation.</p>
<h2 id="pourquoi-la-discrétisation">Pourquoi la discrétisation ?</h2>
<p>L'idée est en fait que la résolution analytique des équations de phénomènes physiques est très complexe et en dehors de cas particuliers ou alors avec des simplifications importantes impossible pour certaines équations comme par exemple celle décrivant des fluides : l'équation de Navier-Stokes<sup><a href="#fn2" class="footnoteRef" id="fnref2">2</a></sup> qui possède de manière générale des termes non-linéaire.</p>
<div class="figure">
<img src="images/tuyere.jpg" title="Résultat de calcul Navier-Stokes instationnaire dans une tuyère, illustrant le caractère tridimensionnel de l&#39;écoulement turbulent en régime de décollement (DAAP - Sébastien Deck)" alt="Résultat de calcul Navier-Stokes instationnaire dans une tuyère, illustrant le caractère tridimensionnel de l&#39;écoulement turbulent en régime de décollement (DAAP - Sébastien Deck)" /><p class="caption">Résultat de calcul Navier-Stokes instationnaire dans une tuyère, illustrant le caractère tridimensionnel de l'écoulement turbulent en régime de décollement (DAAP - Sébastien Deck)</p>
</div>
<p>Comme expliqué sur Wikipédia <sup><a href="#fn3" class="footnoteRef" id="fnref3">3</a></sup> : On dit qu'un système de type entrée-sortie est linéaire ou relève du principe de superposition si:</p>
<ul>
<li>à la somme de deux entrées quelconques correspond la somme des deux sorties correspondantes,</li>
<li>à un multiple d'une entrée quelconque correspond le même multiple de la sortie correspondante.</li>
</ul>
<p>Dans le domaine des systèmes physiques et mécaniques, on appelle souvent l'entrée <em>excitation</em> et la sortie <em>réponse</em>. Plus précisément, si l'on note les excitations <span class="math"><em>f</em></span> (par référence aux forces en mécanique) et les réponses <span class="math"><em>x</em></span> (par référence aux mouvements générés par les forces) :</p>
<ul>
<li>Lorsque l'on sollicite le système par une entrée (excitation) <span class="math"><em>f</em><sub>1</sub></span>, la réponse (déplacement) est <span class="math"><em>x</em><sub>1</sub></span> ;</li>
<li>Lorsque l'on sollicite le système par une entrée (excitation) <span class="math"><em>f</em><sub>2</sub></span>, la réponse (déplacement) est <span class="math"><em>x</em><sub>2</sub></span> ;</li>
</ul>
<p>alors le système est dit linéaire si et seulement si pour <span class="math"><em>λ</em><sub>1</sub></span> et <span class="math"><em>λ</em><sub>2</sub></span> deux nombres quelconques, la réponse à l'excitation <span class="math"><em>λ</em><sub>1</sub>. <em>f</em><sub>1</sub> + <em>λ</em><sub>2</sub>. <em>f</em><sub>2</sub></span> est <span class="math"><em>λ</em><sub>1</sub>. <em>x</em><sub>1</sub> + <em>λ</em><sub>2</sub>. <em>x</em><sub>2</sub></span>.</p>
<p>Je vais présenter un peu en détail la plus simple des trois grandes méthodes de discrétisation (Les différences finies) et j'expliquerais le principe des deux autres (Les éléments finis, Les volumes finis).</p>
<p>Chacune possède une origine spécifique et a pour rôle de permettre la transformation d'un problème basé sur des équations différentielles ou aux dérivés partielles donc plutôt de l'analyse vers un problème de résolution de système linéaire de type :</p>
<p><br /><span class="math"><em>A</em>. <em>x</em> = <em>b</em></span><br /></p>
<p>Où <span class="math"><em>A</em></span> est la matrice qui représente le problème, <span class="math"><em>x</em></span> la solution à trouver et <span class="math"><em>b</em></span> qui représente les conditions initiales/aux limites qui est un problème d'algèbre linéaire.</p>
<p>Le travail que l'on fait finalement quand on part de zéro est donc le suivant :</p>
<ol style="list-style-type: decimal">
<li>On définit les équations du modèle qui représente le phénomène que l'on souhaite étudier avec ses conditions aux limites</li>
<li>On assure que la méthode de discrétisation est capable de fournir une solution unique</li>
<li>On ramène le problème décrit par un modèle basé sur des équations différentielles ou à dérivées partielles à un problème d'algèbre linéaire</li>
<li>On choisit un algorithme qui possède les bonnes propriétés pour la résolution de mon système linéaire</li>
<li>On implémente cet algorithme</li>
<li>On l'exécute (avec ou sans parallélisation)</li>
</ol>
<h2 id="définition-du-domaine">Définition du domaine</h2>
<p>On a déjà parlé dans le premier podcast de ce que l'on entend par modèle, un point qu'il est important de précisé c'est qu'il faut expliquer sur quel domaine ce modèle va s'appliquer (on peut voir en physique par exemple que les théories de la relativité générale et celle de la mécanique quantique par exemple n'ont pas le même domaine d'application) et avec quelles conditions aux limites/initiales.</p>
<p>Assez souvent on va donc donner les équations qui s'appliqueront sur le domaine et on parlera des conditions aux limites pour dire ce qu'il se passe sur les &quot;bords&quot; :</p>
<ul>
<li>une poutre est fixée à un mur</li>
<li>un flux de liquide est présent sur l'entrée d'un tuyau, etc</li>
</ul>
<p>Ces conditions aux limites vont être ainsi de plusieurs types <sup><a href="#fn4" class="footnoteRef" id="fnref4">4</a></sup> :</p>
<ul>
<li><em>Les conditions aux limites en temps</em> : assez souvent on va imposer des conditions à <span class="math"><em>t</em> = 0</span> qui vont par exemple être les conditions initiales d'une simulation en météorologie. On peut aussi imposer des conditions à <span class="math"><em>t</em> =  + inf</span>, mais je n'ai pas trouvé d'exemple assez parlant de l'usage de telles conditions aux limites.</li>
<li><em>Les conditions aux limites en espace</em> : il y en a de différents types, voici les plus classiques :
<ul>
<li>Condition aux limites de Dirichlet<sup><a href="#fn5" class="footnoteRef" id="fnref5">5</a></sup> (nommée d'après Johan Dirichlet, 1805-1859, mathématicien allemand ayant notamment travaillé sur les séries de Fourier, l'arithmétique et on lui doit l'essentiel de la démonstration du dernier théorème de Fermat pour le cas où l'exposant est égal à 5<sup><a href="#fn6" class="footnoteRef" id="fnref6">6</a></sup>) : on spécifie la valeur que va prendre la solution des équations en certaines frontières ou limites du domaine étudié (pour un intervalle <span class="math">[<em>a</em>, <em>b</em>]</span> on aura donc <span class="math"><em>y</em>(<em>a</em>) = <em>α</em></span> et <span class="math"><em>y</em>(<em>b</em>) = <em>β</em></span>). Un exemple est la valeur de la température en <span class="math"><em>a</em></span> pour l'équation de la chaleur.</li>
<li>Conditions aux limites de Neumann<sup><a href="#fn7" class="footnoteRef" id="fnref7">7</a></sup> (nommée d'après Carl Neumann<sup><a href="#fn8" class="footnoteRef" id="fnref8">8</a></sup> et pas John Van Neumann, 1832-925 et il travailla notamment sur les équations intégrales dont l'une des indéterminées est une intégrales et dont les équations de Maxwell sont l'un des plus célèbres représentants<sup><a href="#fn9" class="footnoteRef" id="fnref9">9</a></sup>) : on spécifie la valeur que va prendre la dérivée de la solution des équations en certaines frontières du domaine (pour un intervalle <span class="math">[<em>a</em>, <em>b</em>]</span> on aura donc <span class="math"><em>y</em>ʹ(<em>a</em>) = <em>α</em></span> et <span class="math"><em>y</em>ʹ(<em>b</em>) = <em>β</em></span>). L'exemple est le flux de température, toujours pour l'équation de la chaleur.</li>
<li>Condition aux limites de Robin<sup><a href="#fn10" class="footnoteRef" id="fnref10">10</a></sup> (nommée d'après Victor Gustave Robin, 1855-1897, et non pas notre Robin national, qui a notamment travaillé sur des problèmes de thermodynamique) : ici il s'agit d'imposer aux limites du domaines un relation linéaire entre les valeurs de la fonction et celle de sa dérivée (pour un intervalle <span class="math">[<em>a</em>, <em>b</em>]</span>, on aura donc <span class="math"><em>α</em>. <em>y</em>(<em>a</em>) − <em>β</em>. <em>y</em>ʹ(<em>a</em>) = <em>g</em>(<em>a</em>)</span> et <span class="math"><em>α</em>. <em>y</em>(<em>b</em>) − <em>β</em>. <em>y</em>ʹ(<em>b</em>) = <em>g</em>(<em>b</em>)</span> avec cette fois, <span class="math"><em>α</em></span>, <span class="math"><em>β</em></span> et <span class="math"><em>g</em></span> des fonctions). L'exemple de ce type de condition est un peu plus complexe mais si on reprend notre exemple d'équation de la chaleur, si un bord est en contact avec un autre milieu, les lois de newton et de Fourier précise que le flux de températere à cette interface est proportionnel à la différence de température, mais aussi à la valeur du gradient <sup><a href="#fn11" class="footnoteRef" id="fnref11">11</a></sup>.</li>
</ul></li>
</ul>
<p>A côté de ces conditions aux limites en espace, on en a encore qui sont plus siouxes avec par exempledes conditions aux limites dynamiques qui ressemblent aux conditions de robin, mais qui évoluent au cours du temps et fonction des points de la frontière<sup><a href="#fn12" class="footnoteRef" id="fnref12">12</a></sup>.</p>
<h3 id="différences-finies">Différences finies</h3>
<p>La méthode des différences finies apparaît comme la méthode la plus simple, il s'agit en effet de discrétiser les opérateurs de dérivation/différentiation grâce aux développements de Taylor-Young <sup><a href="#fn13" class="footnoteRef" id="fnref13">13</a></sup> <sup><a href="#fn14" class="footnoteRef" id="fnref14">14</a></sup>. Le mathématicien Brook Taylor établi en 1715 que l'on peut approximer des fonctions suffisamment dérivables au voisinage d'un point par un polynôme dont les coefficients ne dépendent que des dérivées de la fonction en ce point. William Henry Young est arrivé plus tard (1863-1942) lors qu'il travailla sur la théorie de la mesure, les intégrales de Lebesgue etc.</p>
<p>Comme il est question de discrétiser, on peut par exemple regarder ce que cela donne sur un exemple simple :</p>
<ul>
<li>Prenons un segment de longueur 1</li>
<li>On le découpe en <span class="math"><em>n</em> + 1</span> sous-segments dont le pas sera de <span class="math"><em>h</em> = 1 / <em>n</em></span></li>
</ul>
<p>On a grosso modo trois types de différences<sup><a href="#fn15" class="footnoteRef" id="fnref15">15</a></sup> <sup><a href="#fn16" class="footnoteRef" id="fnref16">16</a></sup> :</p>
<ul>
<li>&quot;en avant&quot; : on prend les valeurs en <span class="math"><em>x</em></span> et <span class="math"><em>x</em> + <em>h</em></span></li>
<li>&quot;en arrière&quot; : on prend les valeurs en <span class="math"><em>x</em> − <em>h</em></span> et <span class="math"><em>x</em></span>,</li>
<li>&quot;centrées&quot; : on prend les valeurs en <span class="math"><em>x</em> − <em>h</em> / 2</span> et <span class="math"><em>x</em> + <em>h</em> / 2</span></li>
</ul>
<p>On aura alors comme approximation pour la dérivée de la fonction en <span class="math"><em>x</em></span> :</p>
<p><br /><span class="math">$ f'(x) = \frac{f(x+h)-f(x)}{h} $</span><br /></p>
<p>Ce qui ressemble à l'expression de la dérivée en terme de limite.</p>
<p>En appliquant le même principe à la dérivée première pour obtenir la dérivée second on pour obtenir quelque chose de similaire :</p>
<p><br /><span class="math">$ f''(x) = \frac{f(x+h) - 2f(x) + f(x+h)}{h^2} $</span><br /></p>
<p>Tout ceci fonctionne bien en dimension 1, mais pour peut que les fonctions soient suffisamment dérivables, cela s'étend très bien aux dimensions supérieures.</p>
<p>On voit donc que l'on a besoin des valeurs en différents points qui vont former le maillage et que l'on obtient une relation assez simple pour l'expression des dérivées première, seconde, etc.</p>
<p>Finalement on se rend compte que si notre équation implique par exemple une combinaison linéaire de la dérivée seconde et de la fonction en tout point du domaine:</p>
<p><br /><span class="math"><em>α</em>. <em>f</em>ʺ + <em>β</em>. <em>f</em> = <em>γ</em></span><br /></p>
<p>on se retrouve, grâce aux opérateurs discrétisés à n'avoir affaire qu'à un produit de valeurs de la fonction à trouver qui seront prises en des points définis du maillage.</p>
<p>Ainsi pour tous les points du domaine, on a une une relation entre différentes valeurs de la fonction aux points du maillage. Si on représente par un vecteur <span class="math"><em>f</em></span> dont les différentes valeurs sont celles de la solution aux points du maillage, on peut représenter cela par le produit entre une matrice (qui va exprimer cette relation) et le vecteur qui correspond à la solution. C'est ce système linéaire que l'on cherche ensuite à résoudre avec des algorithmes.</p>
<p>Pour information<sup><a href="#fn17" class="footnoteRef" id="fnref17">17</a></sup> : à partir du 18ème siècle des mathématiciens se sont mis à utiliser des développments de Taylor, et donc les différences finies pour mettre en place des abaques notamment pour les logarithmes et la trigonométrie qui étaient utilisés pour le cadastre, la navigation, l'artillerie, les statistiques, le calcul d'intérêts ou encore l'astronomie. Comme ceux-ci nécessitaient de grands nombres d'opérations de calcul, des mathématiciens et inventeurs se sont mis à tenter la mise en place de machines permettant le calcul &quot;automatique&quot; de ces différences finies. Le premier à presque y arriver fut Charles Baggage entre 1820 et 1843 (il n'y arriva pas complètement) et le Suédois George SCHEUTZ (1785-1873) y arriva en 1840. A savoir que ce type de machine a été utilisé jusque dans les année 1930.</p>
<h3 id="éléments-finis">Éléments finis</h3>
<p>Pour les éléments finis, on n'utilise pas des développements de Taylor-Young comme pour les différences finies qui sont en fait des approximations des dérivées, mais plutôt des approximations des intégrales des équations aux dérivées partielles étudiées.</p>
<p>Dans ce type de discrétisation, il est plutôt question d'approximer la solution sur le maillage par des fonctions qui seront définies sur les éléments du domaine, et uniquement sur ceux-ci. Un peu comme une base de fonctions comme les bases dans <span class="math">R<sup><em>n</em></sup></span>.</p>
<p>Comme décrit dans<sup><a href="#fn18" class="footnoteRef" id="fnref18">18</a></sup>, à l'origine, la méthode des éléments finis était une généralisation de la méthode des déplacements pour les structures à barres, à la mécanique des milieux continus. Depuis cette technique a largement débordé ce premier cadre pour aboutir à une méthode numérique permettant de résoudre les problèmes d'équations différentielles &quot;aux limites&quot;. C'est notamment pour cela que l'on retrouve souvent des histoires de &quot;travail&quot; pour exprimer certaines quantités dans les différentes formulations.</p>
<p>Comme je le disais, ici l'idée est de décomposer le problème sur des bases de fonctions qui sont définies sur les arêtes des &quot;éléments&quot; utilisés pour le maillage, et ensuite d'utiliser la décomposition de la fonction solution sur ce maillage, et par l'usage d'analyse numérique un peu trop poussée pour être explicité ici, on arrive à trouver un système linéaire qui permet d'aboutir à un système linéaire de type <span class="math"><em>A</em>. <em>x</em> = <em>b</em></span>.</p>
<p>Au cours de la discrétisation, on fait ce que l'on appelle une réduction d'ordre de dérivation qui permet d'intégrer les conditions aux limites au sein du système linéaire.</p>
<p>Pour information, cette méthode des éléments finis est extrêment répandu dans les logiciels de simulations pour des domaines variés allant de mécanique des milieux continus, la mécanique des fluides, la météorologie, en génie civil, en électromagnétique, etc.</p>
<p>Pour ceux que cela intéresse, vous pourrez trouver une liste assez longue de cours sur le sujet dans les références<sup><a href="#fn19" class="footnoteRef" id="fnref19">19</a></sup> <sup><a href="#fn20" class="footnoteRef" id="fnref20">20</a></sup> <sup><a href="#fn21" class="footnoteRef" id="fnref21">21</a></sup> <sup><a href="#fn22" class="footnoteRef" id="fnref22">22</a></sup> <sup><a href="#fn23" class="footnoteRef" id="fnref23">23</a></sup>.</p>
<h3 id="volumes-finis">Volumes finis</h3>
<p>De la même manière que pour les éléments finis, la méthode des volumes finis travaille sur les intégrales des EDP étudiées. A la différence des éléments finis où l'on travaille plutôt sur ce que l'on appelle la formulation variationnelle ou formulation faible (on a réduit le niveau de dérivation entre autres) on travaille ici directement sur la formulation forte <sup><a href="#fn24" class="footnoteRef" id="fnref24">24</a></sup>.</p>
<p>En fait, cette méthodes des volumes finis a d'abord été appliquée aux lois de conservation (conservation de la masse, de la quantité de mouvement, etc) qui mettent en jeu un opérateur différentiel nommé <em>divergence</em><sup><a href="#fn25" class="footnoteRef" id="fnref25">25</a></sup>.</p>
<p>Grâce à un théorème dit de flux-divergence<sup><a href="#fn26" class="footnoteRef" id="fnref26">26</a></sup>, on transforme des équations sur des volumes (autour des points du maillage) en des équations sur des surfaces et comme les équations sont conservatives, le flux qui entre est égal au flux qui sort donc cela s'y prête bien.</p>
<p>A la différence des éléments finis, la méthode des volumes finis est simplement utilisable sur des maillages dit non-structurés (comme on ne se soucie pas du maillage, on peut mélanger des triangles avec des carrés, etc. Ceci est plus compliqué avec la méthode des éléments finis).</p>
<h2 id="résolution-de-systèmes-linéaires">Résolution de systèmes linéaires</h2>
<p>Une fois que ces méthodes de discrétisation nous ont permis d'obtenir des systèmes liénaires à résoudre, il est nécessaire de mettre en place des algorithmes de résolution du système obtenu.</p>
<p>Grosso modo, l'idée est d'inverser la matrice <span class="math"><em>A</em></span> pour que l'on puisse se retrouver avec <span class="math"><em>x</em> = <em>A</em><sup> − 1</sup>. <em>b</em></span>. Sauf que cela n'est pas forcément évident quand on parle de matrices. Je ne reviendrais pas sur la question car elle a notamment été abordé dans de précédents podcasts je crois quand il était question de commutativité de la multiplication quand il est question de matrice.</p>
<p>Il existe ainsi différentes méthodes que l'on pourra classer dans deux grandes catégories :</p>
<ul>
<li>Les méthodes directes<sup><a href="#fn27" class="footnoteRef" id="fnref27">27</a></sup></li>
<li>Les méthodes itératives <sup><a href="#fn28" class="footnoteRef" id="fnref28">28</a></sup></li>
</ul>
<p>Je vais ici me concentrer sur les méthodes qui servent à la résolution de systèmes en régime stationnaire (ne dépendant pas du temps). Quand le temps intervient on va utiliser d'autres méthodes comme les méthodes de d'Euler<sup><a href="#fn29" class="footnoteRef" id="fnref29">29</a></sup>, de Crank-Nicolson<sup><a href="#fn30" class="footnoteRef" id="fnref30">30</a></sup>, de Runge-Kutta<sup><a href="#fn31" class="footnoteRef" id="fnref31">31</a></sup>, etc.</p>
<p>A noter un point intéressant : pour certains problèmes stationnaires, on peut-être amené à transformer un problème stationnaire en problème quasi-stationnaire (avec un petit terme en temps qui va apparaître dans la matrice) afin qu'ils soient plus simple à résoudre (le fait que l'on augmente artificiellement les termes sur la diagonale de la matrice améliore la capacité des algorithmes utilisés ensuite à converger vers la bonne solution). On va alors utiliser, pour chaque pas de temps une méthode directe ou itérative pour résoudre une équation à un temps donné, et ensuite une méthode comme celles citées un peu plus haut pour résoudre le problème quasi-stationnaire dont la solution sera celle du problème stationnaire.</p>
<h3 id="les-méthodes-directes">Les méthodes directes</h3>
<p>Les méthodes directives permettent théoriquement d'aboutir à la solution exacte du système liénaire. La plus classique est celle dite du pivot de Gauss ou d'élimination de Gauss-Jordan. Le but est en fait de se débrouille pour arriver à inverser la matrice (en gros). Le problème de ces méthodes, c'est qu'elles peuvent être longues et qu'elles peuvent amener des problèmes numériques pendant l'inversion (notamment quand on va devoir diviser par des nombres petits, des choses comme ça), même si à priori elles permettent d'obtenir la solution exacte.</p>
<h3 id="les-méthodes-itératives.">Les méthodes itératives.</h3>
<p>Celles-ci propose de partir d'une solution <span class="math"><em>x</em><sub>0</sub></span> et d'ensuite minimiser une fonction où entre en jeu la matrice et le second membre. Pour que tout se passe bien, il est nécessaire que <span class="math"><em>x</em><sub>0</sub></span> soit proche de la solution finale.</p>
<p>Une méthode (méthodes dites de Krylov<sup><a href="#fn32" class="footnoteRef" id="fnref32">32</a></sup>) qui trouve différentes implémentations utilisées dans les codes de calcul aujourd'hui est la suivante : L'idée est de définir des vecteurs au fur et à mesure des itérations avec comme contraint qu'ils soient dit conjugué ou orthogonaux avec un certain produit scalaire (où entre en jeu la matrice du système linéaire). Cette condition implique d'ailleurs un certain nombre de propriété sur la matrice du système). L'idée est en fait de créer une base de <span class="math">R<sup><em>n</em></sup></span> avec des vecteurs orthogonaux entre eux et dont la solution en construction est une combinaison linéaire. On voit donc en fait qu'une fois constitué autant de vecteur orthogonaux que la taille de l'espace, on se retrouve avec une solution théoriquement exacte. Les algorithmes les plus connus implémentant cette méthode vont être ceux nommés GMRES, Gradient conjugué<sup><a href="#fn33" class="footnoteRef" id="fnref33">33</a></sup>, etc.</p>
<div class="figure">
<img src="images/500px-Conjugate_gradient_illustration.svg.png" title="Représentation de la convergence de la méthode du gradient conjugué" alt="Représentation de la convergence de la méthode du gradient conjugué" /><p class="caption">Représentation de la convergence de la méthode du gradient conjugué</p>
</div>
<p>A noter que la méthode ADI<sup><a href="#fn34" class="footnoteRef" id="fnref34">34</a></sup> a été l'une des premières qui fut mise en place car elle se basait sur les différences finies (relativement moins complexes que les autres méthodes de discrétisation) et prenait peu de place en mémoire (la matrice avait beaucoup de zéros et seules des bandes le long de la diagonales étaient non-nulles). Ces méthodes peuvent diverger, et il est donc important d'avoir une solution initiale pas trop &quot;mauvaise&quot;, mais aussi que la matrice aient de bonnes propriétés (conditionnement, etc).</p>
<p>Quand les systèmes linéaires à résoudre deviennent trop gros et que l'on a à disposition des serveurs informatiques avec de multiples processeurs, voire même plusieurs serveurs informatiques, on peut paralléliser ces algorithmes.</p>
<p>Pléthore de littérature existe sur la question, et on peut faire ce que l'on appelle de la décomposition de domaine<sup><a href="#fn35" class="footnoteRef" id="fnref35">35</a></sup>. Si on dispose de quatre processeurs et que l'on veut simuler la modification de structure d'un avion en vol, on va par exemple faire calculer la solution sur chaque aile à l'un d'entre eux et on va couper le fuselage en deux pour le distribuer entre les deux processeurs restant.</p>
<p>Dans ces cas-là il devient important de bien découper ses problèmes pour qu'aux frontières tout se passent bien (je rappelle que l'on calcule les solutions aux points des maillages et que si ils ne coincident pas on peut commencer à avoir des problèmes) avec un peu de recouvrement pour que les informations de la solution à chercher puissent se propager entre les &quot;domaines&quot;.</p>
<h2 id="les-solutions-informatiques-qui-existent-et-les-problèmes-afférents">Les solutions informatiques qui existent et les problèmes afférents</h2>
<p>Il existent une grande quantité de librairies logicielles qui existent pour réaliser ces différentes opérations, les plus connues se nomment BLAS<sup><a href="#fn36" class="footnoteRef" id="fnref36">36</a></sup> (pour Basic Linear Algebra Solvers), Linpack ou encore LAPACK<sup><a href="#fn37" class="footnoteRef" id="fnref37">37</a></sup> (pour Linear Algebra Package) qui fournissent des outils pour résoudre des parties des problèmes informatiques.</p>
<p>A savoir que ces librairies ont été écrites en Fortran<sup><a href="#fn38" class="footnoteRef" id="fnref38">38</a></sup>, l'un des tout premiers langages informatiques de haut-niveau créé dans les années 50 et encore toujours roi dans le monde de la simulation informatique.</p>
<p>Je l'ai survolé, mais l'informatique en terme de matériel et de logiciel a évolué de manière conjointe. Comme je l'expliquais, on est passé de discrétisation avec des différences finies et des méthodes de type ADI peu gourmande en mémoire dans les années 50-60, à des méthodes plus complexes comme les éléments finis par la suite. On a vu aussi grandir les maillages qui n'avait que de petites tailles pour des problèmes de taille mémoire et disque à des problèmes qui font maintenant plusieurs dizaines voire centaines de millions d'inconnues et qui prennent ainsi plusieurs giga-octets de RAM. On a aussi du paralléliser les algorithmes pour pouvoir tirer partie des super-calculateur et leur puissance répartie.</p>
<p>Petite anecdote marrante : en 2006 j'ai fait un stage dans une société qui faisait de la simulation et un cas marquant était celui de la simulation du décollage d'un hélicoptère à turbo-réacteur. Le calcul était tellement complexe qu'il fallait près de 24 heures pour que le logiciel simule quelques dixièmes de seconde avant d'exploser sur près de 50 serveurs !</p>
<p>C'est dire la complexité des modèles considérés et des contraintes informatiques (autant logicielles que matérielles) qui existent !</p>
<p>D'ailleurs un des problèmes qui est apparu est la question des données. J'ai parlé lors du précédent podcast de la simulation de l'univers, avec les données gigantesques générées (1,5 peta-octet utile). Ce qu'il faut savoir c'est qu'il y a eu près de 100x plus de données générées qu'il a fallu trier !!!</p>
<h2 id="les-cartes-graphiques-pour-aider-dans-la-simulation">Les cartes graphiques pour aider dans la simulation</h2>
<p>Quelque chose qui s'est développé ces dernières années à notamment été l'usage des cartes graphiques pour aider au calcul. En tant que solution de traitement parallèle massif, les GPUs de ces cartes peuvent avoir de vrais atouts.</p>
<p>Il y a quand même quelques inconvénients :</p>
<ul>
<li>Avant que qu'OpenCL<sup><a href="#fn39" class="footnoteRef" id="fnref39">39</a></sup> n'arrive, voire même CUDA <sup><a href="#fn40" class="footnoteRef" id="fnref40">40</a></sup> avant lui (deux &quot;langages dédié à l'usage de GPU&quot;) il était nécessaire de manier les structures de données propres aux jeux vidéos pour en tirer partie. Ce n'était pas très évident et plus du domaine de la bidouille qu'autre chose. Maintenant cela est plus simple, et un certain nombre de code de calcul se mettent à en tirer partie.</li>
<li>Cependant les limitations en terme de mémoire de ces cartes (si on a plus de données que la place disponible dans la carte, on va adresser la mémoire centrale de l'ordinateur et l'on perd tout l'intérêt) et de précision numérique (les cartes ne calcul qu'avec des entiers de base et pas des nombres réels) font que les performances mirobolantes annoncées par Nvidia notamment en font revenir plus d'un vers le calcul plus classique</li>
</ul>
<p>Une des alternatives qui commence à arriver serait l'usage (comme il y a bien longtemps) de co-processeurs spécialisés à cette tâche comme les Xeon-Phi<sup><a href="#fn41" class="footnoteRef" id="fnref41">41</a></sup> de chez Intel.</p>
<h2 id="linpack-le-top500-le-green500">Linpack, le top500, le green500</h2>
<p>Un effet collatéral étonnant a été que l'usage de la librairie Linpack pour évaluer la performance crête des super-calculateurs. L'idée était en effet de mesure la performance des systèmes informatiques pour la résolution d'un système liénaire basé sur les fonctions fournies par la librairie.</p>
<p>Pendant longtemps ce logiciel a été à la base du Top500<sup><a href="#fn42" class="footnoteRef" id="fnref42">42</a></sup>, le classement des 500 calculateurs les plus puissants du monde. Puis avec l'avènement des cartes graphiques qui en puissance brute sont intéressantes, mais en usage réel assez peu utilisables et les problématiques de grandes données qui ne sont pas très bien prises en compte par ce test<sup><a href="#fn43" class="footnoteRef" id="fnref43">43</a></sup>, différents autres classements sont apparus avec le Green500 <sup><a href="#fn44" class="footnoteRef" id="fnref44">44</a></sup> notamment qui estime plutôt la performance énergétique d'un système informatique.</p>
<p>Il est en effet devenu crucial de gérer correctement les problématiques d'énergie, car la puissance de calcul de ces moyens informatiques gradissant, la consommation énergétique va de pair et ceci sans parler de la consommation électrique des climatisations nécessaires pour refroidir les serveurs. Pour info, aujourd'hui, il faut quasiment autant d'énergie pour la climatisation que pour les serveurs.</p>
<p>Avec près de 17 000 coeurs de calcul au CC-IN2P3<sup><a href="#fn45" class="footnoteRef" id="fnref45">45</a></sup> (le centre de calcul qui possédait les données du LHC concernant le boson de Higgs) et les 20 Peta-octets de stockage sur disque et sur bande, il est nécessaire de disposer d'une alimentation de plusieurs mégawatts !</p>
<h1 id="conclusions">Conclusions</h1>
<p>Voilà, j'ai tenté de dresser un panorama de ce que me semble être la simulation numérique avec :</p>
<ul>
<li>Un premier podcast plutôt général sur la simulation, les problématiques auxquelles elle tente de répondre, avec quelques exemples et notamment la première qui fut mise en place dans les années 50.</li>
<li>Un second plutôt cette fois orienté sur les méthodes dédiées aux EDP avec des infos plus mathématiques et informatiques sur les méthodes de discrétisations, comment on implémente cela sur des serveurs et finalement quelques digressions plus large sur les impacts des technologies dans le domaine.</li>
</ul>
<p>Il est finalement important de voir que la simulation :</p>
<ul>
<li>Est indispensable pour la science aujourd'hui pour continuer de comprendre les phénomènes qui nous entoure, et que cela ne va pas aller en diminuant</li>
<li>Est la source de nouveaux challenges qui ont des impacts dans nos vies de tous les jours (Cloud, Big Data, etc)</li>
<li>Est sortie depuis longtemps du domaine scientifique et le monde du jeu vidéo profite depuis quelques années des avancées dans ce domaine, MS Flight Simulator était l'un des premiers, maintenant on parle notamment de moteur physique, de simulation de vagues, etc. GTA IV en est un des exemples les plus récents.</li>
</ul>
<p>En espérant que vous aurez appris plein de choses et que vous aurez trouver cela intéressant, je vous remercie de m'avoir laissé en parlé :)</p>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p><a href="http://fr.wikipedia.org/wiki/Simulation_informatique">http://fr.wikipedia.org/wiki/Simulation_informatique</a><a href="#fnref1">↩</a></p></li>
<li id="fn2"><p><a href="http://fr.wikipedia.org/wiki/%C3%89quations_de_Navier-Stokes">http://fr.wikipedia.org/wiki/%C3%89quations_de_Navier-Stokes</a><a href="#fnref2">↩</a></p></li>
<li id="fn3"><p><a href="http://fr.wikipedia.org/wiki/Principe_de_superposition">http://fr.wikipedia.org/wiki/Principe_de_superposition</a><a href="#fnref3">↩</a></p></li>
<li id="fn4"><p><a href="http://fr.wikipedia.org/wiki/Condition_aux_limites">http://fr.wikipedia.org/wiki/Condition_aux_limites</a><a href="#fnref4">↩</a></p></li>
<li id="fn5"><p><a href="http://fr.wikipedia.org/wiki/Condition_aux_limites_de_Dirichlet">http://fr.wikipedia.org/wiki/Condition_aux_limites_de_Dirichlet</a><a href="#fnref5">↩</a></p></li>
<li id="fn6"><p><a href="http://fr.wikipedia.org/wiki/Dirichlet">http://fr.wikipedia.org/wiki/Dirichlet</a><a href="#fnref6">↩</a></p></li>
<li id="fn7"><p><a href="http://fr.wikipedia.org/wiki/Condition_aux_limites_de_Neumann">http://fr.wikipedia.org/wiki/Condition_aux_limites_de_Neumann</a><a href="#fnref7">↩</a></p></li>
<li id="fn8"><p><a href="http://fr.wikipedia.org/wiki/Carl_Neumann">http://fr.wikipedia.org/wiki/Carl_Neumann</a><a href="#fnref8">↩</a></p></li>
<li id="fn9"><p><a href="http://fr.wikipedia.org/wiki/%C3%89quation_int%C3%A9grale">http://fr.wikipedia.org/wiki/%C3%89quation_int%C3%A9grale</a><a href="#fnref9">↩</a></p></li>
<li id="fn10"><p><a href="http://fr.wikipedia.org/wiki/Condition_aux_limites_de_Robin">http://fr.wikipedia.org/wiki/Condition_aux_limites_de_Robin</a><a href="#fnref10">↩</a></p></li>
<li id="fn11"><p><a href="http://www.cmi.univ-mrs.fr/~torresan/MathPhy/cours/node16.html#SECTION0033320000000000000000">http://www.cmi.univ-mrs.fr/~torresan/MathPhy/cours/node16.html#SECTION0033320000000000000000</a><a href="#fnref11">↩</a></p></li>
<li id="fn12"><p><a href="http://fr.wikipedia.org/wiki/Condition_aux_limites_dynamique">http://fr.wikipedia.org/wiki/Condition_aux_limites_dynamique</a><a href="#fnref12">↩</a></p></li>
<li id="fn13"><p><a href="http://fr.wikipedia.org/wiki/Th%C3%A9or%C3%A8me_de_Taylor">http://fr.wikipedia.org/wiki/Th%C3%A9or%C3%A8me_de_Taylor</a><a href="#fnref13">↩</a></p></li>
<li id="fn14"><p><a href="http://fr.wikipedia.org/wiki/Brook_Taylor">http://fr.wikipedia.org/wiki/Brook_Taylor</a><a href="#fnref14">↩</a></p></li>
<li id="fn15"><p><a href="http://fr.wikipedia.org/wiki/Diff%C3%A9rence_finie">http://fr.wikipedia.org/wiki/Diff%C3%A9rence_finie</a><a href="#fnref15">↩</a></p></li>
<li id="fn16"><p><a href="http://fr.wikipedia.org/wiki/M%C3%A9thode_des_diff%C3%A9rences_finies">http://fr.wikipedia.org/wiki/M%C3%A9thode_des_diff%C3%A9rences_finies</a><a href="#fnref16">↩</a></p></li>
<li id="fn17"><p><a href="http://pauillac.inria.fr/~weis/info/histoire_de_l_info.html">http://pauillac.inria.fr/~weis/info/histoire_de_l_info.html</a><a href="#fnref17">↩</a></p></li>
<li id="fn18"><p>docinsa<a href="#fnref18">↩</a></p></li>
<li id="fn19"><p><a href="http://fr.wikibooks.org/wiki/M%C3%A9thode_des_%C3%A9l%C3%A9ments_finis/Formulation">http://fr.wikibooks.org/wiki/M%C3%A9thode_des_%C3%A9l%C3%A9ments_finis/Formulation</a><a href="#fnref19">↩</a></p></li>
<li id="fn20"><p><a href="http://fr.wikibooks.org/wiki/M%C3%A9thode_des_%C3%A9l%C3%A9ments_finis/Rappels_de_m%C3%A9canique">http://fr.wikibooks.org/wiki/M%C3%A9thode_des_%C3%A9l%C3%A9ments_finis/Rappels_de_m%C3%A9canique</a><a href="#fnref20">↩</a></p></li>
<li id="fn21"><p><a href="http://fr.wikibooks.org/wiki/M%C3%A9thode_des_%C3%A9l%C3%A9ments_finis/Pr%C3%A9sentation_g%C3%A9n%C3%A9rale">http://fr.wikibooks.org/wiki/M%C3%A9thode_des_%C3%A9l%C3%A9ments_finis/Pr%C3%A9sentation_g%C3%A9n%C3%A9rale</a><a href="#fnref21">↩</a></p></li>
<li id="fn22"><p><a href="http://fr.wikipedia.org/wiki/M%C3%A9thode_des_%C3%A9l%C3%A9ments_finis">http://fr.wikipedia.org/wiki/M%C3%A9thode_des_%C3%A9l%C3%A9ments_finis</a><a href="#fnref22">↩</a></p></li>
<li id="fn23"><p><a href="http://laurent.baillet.voila.net/cours_Dyna_struct.pdf">http://laurent.baillet.voila.net/cours_Dyna_struct.pdf</a><a href="#fnref23">↩</a></p></li>
<li id="fn24"><p><a href="http://fr.wikipedia.org/wiki/M%C3%A9thode_des_volumes_finis">http://fr.wikipedia.org/wiki/M%C3%A9thode_des_volumes_finis</a><a href="#fnref24">↩</a></p></li>
<li id="fn25"><p><a href="http://fr.wikipedia.org/wiki/Divergence_(analyse_vectorielle)">http://fr.wikipedia.org/wiki/Divergence_(analyse_vectorielle)</a><a href="#fnref25">↩</a></p></li>
<li id="fn26"><p><a href="http://fr.wikipedia.org/wiki/Th%C3%A9or%C3%A8me_de_flux-divergence">http://fr.wikipedia.org/wiki/Th%C3%A9or%C3%A8me_de_flux-divergence</a><a href="#fnref26">↩</a></p></li>
<li id="fn27"><p><a href="http://sfb649.wiwi.hu-berlin.de/fedc_homepage/xplore/ebooks/html/csa/node37.html">http://sfb649.wiwi.hu-berlin.de/fedc_homepage/xplore/ebooks/html/csa/node37.html</a><a href="#fnref27">↩</a></p></li>
<li id="fn28"><p><a href="http://en.wikipedia.org/wiki/Iterative_method">http://en.wikipedia.org/wiki/Iterative_method</a><a href="#fnref28">↩</a></p></li>
<li id="fn29"><p><a href="http://en.wikipedia.org/wiki/Backward_Euler_method">http://en.wikipedia.org/wiki/Backward_Euler_method</a><a href="#fnref29">↩</a></p></li>
<li id="fn30"><p><a href="http://en.wikipedia.org/wiki/Crank%E2%80%93Nicolson_method">http://en.wikipedia.org/wiki/Crank%E2%80%93Nicolson_method</a><a href="#fnref30">↩</a></p></li>
<li id="fn31"><p><a href="http://en.wikipedia.org/wiki/Runge%E2%80%93Kutta_methods">http://en.wikipedia.org/wiki/Runge%E2%80%93Kutta_methods</a><a href="#fnref31">↩</a></p></li>
<li id="fn32"><p><a href="http://en.wikipedia.org/wiki/Krylov_subspace">http://en.wikipedia.org/wiki/Krylov_subspace</a><a href="#fnref32">↩</a></p></li>
<li id="fn33"><p><a href="http://en.wikipedia.org/wiki/Conjugate_gradient">http://en.wikipedia.org/wiki/Conjugate_gradient</a><a href="#fnref33">↩</a></p></li>
<li id="fn34"><p><a href="http://en.wikipedia.org/wiki/Alternating_direction_implicit_method">http://en.wikipedia.org/wiki/Alternating_direction_implicit_method</a><a href="#fnref34">↩</a></p></li>
<li id="fn35"><p><a href="http://en.wikipedia.org/wiki/Domain_decomposition_methods">http://en.wikipedia.org/wiki/Domain_decomposition_methods</a><a href="#fnref35">↩</a></p></li>
<li id="fn36"><p><a href="http://www.netlib.org/blas/">http://www.netlib.org/blas/</a><a href="#fnref36">↩</a></p></li>
<li id="fn37"><p><a href="http://www.netlib.org/lapack/">http://www.netlib.org/lapack/</a><a href="#fnref37">↩</a></p></li>
<li id="fn38"><p><a href="http://fr.wikipedia.org/wiki/Fortran">http://fr.wikipedia.org/wiki/Fortran</a><a href="#fnref38">↩</a></p></li>
<li id="fn39"><p><a href="http://fr.wikipedia.org/wiki/OpenCL">http://fr.wikipedia.org/wiki/OpenCL</a><a href="#fnref39">↩</a></p></li>
<li id="fn40"><p><a href="http://fr.wikipedia.org/wiki/Compute_Unified_Device_Architecture">http://fr.wikipedia.org/wiki/Compute_Unified_Device_Architecture</a><a href="#fnref40">↩</a></p></li>
<li id="fn41"><p><a href="http://www.intel.fr/content/www/fr/fr/processors/xeon/xeon-phi-detail.html">http://www.intel.fr/content/www/fr/fr/processors/xeon/xeon-phi-detail.html</a><a href="#fnref41">↩</a></p></li>
<li id="fn42"><p><a href="http://www.top500.org/">http://www.top500.org/</a><a href="#fnref42">↩</a></p></li>
<li id="fn43"><p><a href="http://www.zdnet.fr/actualites/supercalculateurs-le-top500-annonce-un-changement-de-methode-de-calcul-39792356.htm">http://www.zdnet.fr/actualites/supercalculateurs-le-top500-annonce-un-changement-de-methode-de-calcul-39792356.htm</a><a href="#fnref43">↩</a></p></li>
<li id="fn44"><p><a href="http://www.green500.org/">http://www.green500.org/</a><a href="#fnref44">↩</a></p></li>
<li id="fn45"><p><a href="http://cc.in2p3.fr/Le-parc-informatique">http://cc.in2p3.fr/Le-parc-informatique</a><a href="#fnref45">↩</a></p></li>
</ol>
</div>
</body>
</html>
